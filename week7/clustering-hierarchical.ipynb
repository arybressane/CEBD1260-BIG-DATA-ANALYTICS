{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scipy\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import collections\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster countries by happiness scored according to economic production, social support, etc.\n",
    "\n",
    "https://www.kaggle.com/unsdsn/world-happiness\n",
    "\n",
    "http://worldhappiness.report/ed/2017/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/wh_2017.csv')\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns\n",
    "X_columns = ['Happiness.Score', 'Economy..GDP.per.Capita.']\n",
    "\n",
    "# normalize the data\n",
    "for col in X_columns:\n",
    "    df[col] = StandardScaler().fit_transform(df[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "color_threshold = 8.\n",
    "d = sch.distance.pdist(df[X_columns])\n",
    "Z= sch.linkage(d, method = 'ward') # minimize within cluster variation\n",
    "T = sch.fcluster(Z, k, 'maxclust')\n",
    "P = sch.dendrogram(Z, color_threshold=color_threshold)\n",
    "plt.show()\n",
    "\n",
    "print(set(T))\n",
    "print(collections.Counter(T))\n",
    "\n",
    "df_results = df.copy()\n",
    "df_results['cluster'] = T\n",
    "df['cluster'] = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results\n",
    "for cluster in set(T):\n",
    "    print((cluster), (len(df_results[df_results['cluster']==cluster]['Country'])))\n",
    "    print(sorted(list(df_results[df_results['cluster']==cluster]['Country'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the centroids\n",
    "df_results.groupby('cluster').mean().round(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results\n",
    "for col in X_columns:\n",
    "    print(col)\n",
    "    for cluster in set(T):\n",
    "        plt.hist(df_results[df_results['cluster']==cluster][col], label=str(cluster), alpha=0.3, bins=20)\n",
    "    #plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the results\n",
    "n_clusters = len(set(T))\n",
    "print(n_clusters)\n",
    "for col in X_columns:\n",
    "    print(col)\n",
    "    i = 1\n",
    "    plt.figure(figsize=(16,3))\n",
    "    for cluster in sorted(set(T)):\n",
    "        plt.subplot(1, n_clusters, i)\n",
    "        plt.xlim([0,df_results[col].max()])\n",
    "        plt.hist(df_results[df_results['cluster']==cluster][col], label=str(cluster), alpha=0.3, bins=10)\n",
    "        i += 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analyze the correlation with Happiness Score\n",
    "for c in ['Happiness.Score', 'Economy..GDP.per.Capita.', 'Family', 'Health..Life.Expectancy.', 'Freedom', 'Generosity', 'Trust..Government.Corruption.', 'Dystopia.Residual']:\n",
    "    print(c)\n",
    "    plt.plot(df_results['Happiness.Score'], df_results[c], 'o')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inter-Cluster\n",
    "centroids = []\n",
    "for cluster in sorted(set(T)):\n",
    "    centroids.append(df[df['cluster']==cluster][X_columns].mean().values)\n",
    "distances = []\n",
    "for c1 in centroids:\n",
    "    for c2 in centroids:\n",
    "        distances.append(euclidean_distances(c1.reshape(-1, 1), c2.reshape(-1, 1))[0][0])\n",
    "print('Inter Cluster distance', np.mean(distances))\n",
    "\n",
    "# Intra-Cluster\n",
    "distances = []\n",
    "for cluster in sorted(set(T)):\n",
    "    df_filter = df[df['cluster']==cluster]\n",
    "    centroid = df_filter[X_columns].mean().values\n",
    "    for k, v in df_filter[X_columns].iterrows():\n",
    "        distances.append(euclidean_distances(centroid.reshape(-1, 1), v.values.reshape(-1, 1))[0][0])\n",
    "print('Intra Cluster distance', np.mean(distances))\n",
    "\n",
    "# Inertia\n",
    "distances = []\n",
    "for cluster in sorted(set(T)):\n",
    "    df_filter = df[df['cluster']==cluster]\n",
    "    centroid = df_filter[X_columns].mean().values\n",
    "    for k, v in df_filter[X_columns].iterrows():\n",
    "        distances.append(euclidean_distances(centroid.reshape(1, -1), v.values.reshape(1, -1), squared=True)[0][0])\n",
    "print('Inertia', np.sum(distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "number_k = []\n",
    "for k in range(2,100,10):\n",
    "    d = sch.distance.pdist(df[X_columns])\n",
    "    Z= sch.linkage(d, method = 'ward')\n",
    "    T = sch.fcluster(Z, k, 'maxclust')\n",
    "    df['cluster'] = T\n",
    "\n",
    "    # Inertia\n",
    "    distances = []\n",
    "    for cluster in sorted(set(T)):\n",
    "        df_filter = df[df['cluster']==cluster]\n",
    "        centroid = df_filter[X_columns].mean().values\n",
    "        for _, v in df_filter[X_columns].iterrows():\n",
    "            distances.append(euclidean_distances(centroid.reshape(1, -1), v.values.reshape(1, -1), squared=True)[0][0])\n",
    "    inertia.append(np.sum(distances))\n",
    "    number_k.append(k)\n",
    "plt.plot(number_k, inertia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
