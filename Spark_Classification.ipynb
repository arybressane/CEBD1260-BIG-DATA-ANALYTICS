{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark Classification",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arybressane/CEBD1260-BIG-DATA-ANALYTICS/blob/master/Spark_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2-iFjHqgPfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget http://apache.forsale.plus/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!tar xvf spark-2.4.3-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe3bAmEonnbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.3-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2Gv8kagnnrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey6gJnJpnnwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY29kuq9nn0Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the library\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjfsqIGgqIav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import spark libraries\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_4ib9icqIeI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7a9b9d75-3d51-49c4-ffe5-c5f00541a7f8"
      },
      "source": [
        "# Load and parse the data file, converting it to a DataFrame.\n",
        "data = spark.read.csv('default of credit card clients.txt', header = True, inferSchema = True)\n",
        "data.show"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.show of DataFrame[ID: int, LIMIT_BAL: int, SEX: int, EDUCATION: int, MARRIAGE: int, AGE: int, PAY_0: int, PAY_2: int, PAY_3: int, PAY_4: int, PAY_5: int, PAY_6: int, BILL_AMT1: int, BILL_AMT2: int, BILL_AMT3: int, BILL_AMT4: int, BILL_AMT5: int, BILL_AMT6: int, PAY_AMT1: int, PAY_AMT2: int, PAY_AMT3: int, PAY_AMT4: int, PAY_AMT5: int, PAY_AMT6: int, default payment next month: int]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcHZfwZuqIg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# feature engineering\n",
        "X_columns = data.columns[:-1]\n",
        "y_column = data.columns[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV1sW-iSqIjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the features column\n",
        "vecAssembler = VectorAssembler(inputCols=X_columns, outputCol=\"features\")\n",
        "data = vecAssembler.transform(data)\n",
        "\n",
        "# Split the data into training and test sets (80% held out for testing)\n",
        "(trainingData, testData) = data.randomSplit([0.8, 0.2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vLCcvg6qImf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "961437bb-214d-42b4-ee32-a3b5b4578bfc"
      },
      "source": [
        "# Train a RandomForest model.\n",
        "rf = RandomForestClassifier(labelCol=y_column, numTrees=100)\n",
        "\n",
        "# Chain indexer and forest in a Pipeline\n",
        "pipeline = Pipeline(stages=[rf])\n",
        "\n",
        "# Train model.  This also runs the indexer.\n",
        "model = pipeline.fit(trainingData)\n",
        "\n",
        "# Make predictions.\n",
        "predictions = model.transform(testData)\n",
        "\n",
        "# Select example rows to display.\n",
        "predictions.select(\"prediction\", y_column, \"features\").show(5)\n",
        "\n",
        "rfModel = model.stages\n",
        "print(rfModel)  # summary only"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+--------------------------+--------------------+\n",
            "|prediction|default payment next month|            features|\n",
            "+----------+--------------------------+--------------------+\n",
            "|       0.0|                         0|[3.0,90000.0,2.0,...|\n",
            "|       0.0|                         0|[4.0,50000.0,2.0,...|\n",
            "|       0.0|                         0|[6.0,50000.0,1.0,...|\n",
            "|       0.0|                         0|[10.0,20000.0,1.0...|\n",
            "|       0.0|                         0|[12.0,260000.0,2....|\n",
            "+----------+--------------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "[RandomForestClassificationModel (uid=RandomForestClassifier_dfdce7b2bb44) with 100 trees]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWbBsV0mqiw5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "9daedb26-d1c2-480d-df20-1008ce88fc1d"
      },
      "source": [
        "# Select (prediction, true label) and compute test error\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=y_column, predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
        "mae = evaluator.evaluate(predictions)\n",
        "print(\"Precision on test data = %g\" % mae)\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=y_column, predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Recall on test data = %g\" % rmse)\n",
        "\n",
        "rfModel = model.stages\n",
        "print(rfModel)  # summary only"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision on test data = 0.785172\n",
            "Recall on test data = 0.805968\n",
            "[RandomForestClassificationModel (uid=RandomForestClassifier_dfdce7b2bb44) with 100 trees]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}